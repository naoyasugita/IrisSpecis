{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ライブラリのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# pd.options.display.max_columns = 32\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データセットのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal length  sepal width  petal length  petal width\n",
      "0           5.1          3.5           1.4          0.2\n",
      "1           4.9          3.0           1.4          0.2\n",
      "2           4.7          3.2           1.3          0.2\n",
      "3           4.6          3.1           1.5          0.2\n",
      "4           5.0          3.6           1.4          0.2\n",
      "   target\n",
      "0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       0\n"
     ]
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = pd.DataFrame(iris.data)\n",
    "X.columns = [\"sepal length\",\"sepal width\",\"petal length\",\"petal width\"] \n",
    "print(X.head())\n",
    "T = pd.DataFrame(iris.target)\n",
    "T.columns = [\"target\"] \n",
    "print(T.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]\n",
      " [1.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "features = iris.data\n",
    "targets = iris.target \n",
    "\n",
    "from keras.utils import np_utils\n",
    "targets = np_utils.to_categorical(targets[:3])\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'sklearn.model_selection'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-f1bb1ac45947>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'sklearn.model_selection'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.utils import np_utils\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def build_multilayer_perceptron():\n",
    "    \"\"\"多層パーセプトロンモデルを構築\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16, input_shape=(4, )))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(3))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Irisデータをロード\n",
    "    iris = datasets.load_iris()\n",
    "    X = iris.data\n",
    "    Y = iris.target\n",
    "\n",
    "    # データの標準化\n",
    "    X = preprocessing.scale(X)\n",
    "\n",
    "    # ラベルをone-hot-encoding形式に変換\n",
    "    # 0 => [1, 0, 0]\n",
    "    # 1 => [0, 1, 0]\n",
    "    # 2 => [0, 0, 1]\n",
    "    Y = np_utils.to_categorical(Y)\n",
    "\n",
    "    # 訓練データとテストデータに分割\n",
    "    train_X, test_X, train_Y, test_Y = train_test_split(X, Y, train_size=0.8)\n",
    "    print(train_X.shape, test_X.shape, train_Y.shape, test_Y.shape)\n",
    "\n",
    "    # モデル構築\n",
    "    model = build_multilayer_perceptron()\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # モデル訓練\n",
    "    model.fit(train_X, train_Y, nb_epoch=50, batch_size=1, verbose=1)\n",
    "\n",
    "    # モデル評価\n",
    "    loss, accuracy = model.evaluate(test_X, test_Y, verbose=0)\n",
    "    print(\"Accuracy = {:.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
